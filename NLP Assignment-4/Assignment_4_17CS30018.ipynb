{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Assignment-4 NLP : POS TAGGING USING CRFSuite**\n",
    "\n",
    "**Name     :  Kanishk Singh**\n",
    "\n",
    "**Roll No  :  17CS30018**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn-crfsuite in /home/kanishk/miniconda3/lib/python3.7/site-packages (0.3.6)\n",
      "Requirement already satisfied: tqdm>=2.0 in /home/kanishk/miniconda3/lib/python3.7/site-packages (from sklearn-crfsuite) (4.36.1)\n",
      "Requirement already satisfied: tabulate in /home/kanishk/miniconda3/lib/python3.7/site-packages (from sklearn-crfsuite) (0.8.7)\n",
      "Requirement already satisfied: python-crfsuite>=0.8.3 in /home/kanishk/miniconda3/lib/python3.7/site-packages (from sklearn-crfsuite) (0.9.7)\n",
      "Requirement already satisfied: six in /home/kanishk/miniconda3/lib/python3.7/site-packages (from sklearn-crfsuite) (1.12.0)\n"
     ]
    }
   ],
   "source": [
    "#installing sklearn-crfsuite\n",
    "!pip install sklearn-crfsuite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import metrics,CRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to preprocess the TRAINING AND TEST DATA\n",
    "\n",
    "def fileread(filename, delimiter):\n",
    "    sentences = []\n",
    "    with open(filename, \"r\") as f:\n",
    "        sentence = []\n",
    "        #print(len(f.readlines()))\n",
    "        for tag in f.readlines()[1:]:\n",
    "            eos = delimiter+delimiter+'\\n'\n",
    "            if tag == eos:\n",
    "                sentences.append(sentence)\n",
    "                sentence = []\n",
    "                continue\n",
    "            fields = tag.strip().split(delimiter)\n",
    "            sample_word = (fields[1].strip('\\\"'), fields[2])\n",
    "            #print(sample_word)\n",
    "            sentence.append(sample_word)\n",
    "        sentences.append(sentence)\n",
    "    #print(fields)\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Word_To_Features(sentence,index_of_word)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def WordToFeatures(sentence, index):\n",
    "    Word = sentence[index][0]\n",
    "    \n",
    "    features = {\n",
    "        'Word':           Word,\n",
    "        'Word.Lower()':   Word.lower(),\n",
    "        'Word.isTitle()': Word.istitle(),\n",
    "        'Word.isUpper()': Word.isupper(),\n",
    "        'Word.isDigit()': Word.isdigit(),\n",
    "        'Prefix-3':       Word[:3] if len(Word)>2 else '',\n",
    "        'Suffix-3':       Word[-3:] if len(Word)>2 else '',\n",
    "        'has_Hyphen':     '-' in Word,\n",
    "    }\n",
    "    \n",
    "    if (index > 0):\n",
    "        PrevWord = sentence[index-1][0]\n",
    "        features.update({\n",
    "            '-1:Word.Lower()'   : PrevWord.lower(),\n",
    "            '-1:Word.isTitle()' : PrevWord.istitle(),\n",
    "            '-1:Word.isUpper()' : PrevWord.isupper(),\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True\n",
    "\n",
    "    if (index < len(sentence)-1):\n",
    "        NextWord = sentence[index+1][0]\n",
    "        features.update({\n",
    "            '+1:Word.Lower()'   : NextWord.lower(),\n",
    "            '+1:Word.isTitle()' : NextWord.istitle(),\n",
    "            '+1:Word.isUpper()' : NextWord.isupper(),\n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sent_To_Features(sentence):\n",
    "    return [WordToFeatures(sentence, i) for i in range(len(sentence))]\n",
    "\n",
    "def Sent_To_Labels(sentence):\n",
    "    return [fields[1] for fields in sentence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mAssignment_4_17CS30018\u001b[0m/       hi-ud-test .conllu\r\n",
      "Assignment_4_17CS30018.ipynb  hi-ud-train (1).conllu\r\n",
      "Assignment_4_17CS30018.pdf    hi-ud-train.conllu\r\n",
      "\u001b[01;31mAssignment_4_17CS30018.zip\u001b[0m    \u001b[01;35mModel_on_test.png\u001b[0m\r\n",
      "Assignment4_NLP.pdf           \u001b[01;35mmodel_prediction_train.png\u001b[0m\r\n",
      "Assignment4_YourRollNo.docx   \u001b[01;35mmost-and-least-common.png\u001b[0m\r\n",
      "hi-ud-test  (1).conllu\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_Set   = fileread('hi-ud-train.conllu', ',')\n",
    "Test_Set    = fileread('hi-ud-test .conllu', '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train     = [Sent_To_Features(sent) for sent in Train_Set]\n",
    "y_train     = [Sent_To_Labels(sent)   for sent in Train_Set]\n",
    "\n",
    "x_test      = [Sent_To_Features(sent) for sent in Test_Set]\n",
    "y_test      = [Sent_To_Labels(sent)   for sent in Test_Set]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MODEL ON TRAINING_DATA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kanishk/miniconda3/lib/python3.7/site-packages/sklearn/base.py:197: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CRF(algorithm='lbfgs', all_possible_states=None, all_possible_transitions=True,\n",
       "    averaging=None, c=None, c1=0.1, c2=0.1, calibration_candidates=None,\n",
       "    calibration_eta=None, calibration_max_trials=None, calibration_rate=None,\n",
       "    calibration_samples=None, delta=None, epsilon=None, error_sensitive=None,\n",
       "    gamma=None, keep_tempfiles=None, linesearch=None, max_iterations=300,\n",
       "    max_linesearch=None, min_freq=None, model_filename=None, num_memories=None,\n",
       "    pa_type=None, period=None, trainer_cls=None, variance=None, verbose=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model = CRF(    \n",
    "    algorithm      = 'lbfgs',\n",
    "    c1             = 0.1,\n",
    "    c2             = 0.1,\n",
    "    max_iterations = 300,\n",
    "    all_possible_transitions = True\n",
    ")\n",
    "Model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RUNNING THE MODEL ON THE TRAINING_DATA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        MODEL PREDICTION ON TRAINING DATA         \n",
      "--------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ       1.00      1.00      1.00       570\n",
      "         ADP       1.00      1.00      1.00      1387\n",
      "         ADV       0.97      0.98      0.98       111\n",
      "         AUX       0.99      1.00      0.99       730\n",
      "       CCONJ       0.99      1.00      1.00       150\n",
      "       COMMA       1.00      1.00      1.00       114\n",
      "         DET       1.00      0.99      0.99       231\n",
      "        NOUN       1.00      1.00      1.00      1597\n",
      "         NUM       1.00      1.00      1.00       152\n",
      "        PART       1.00      1.00      1.00       163\n",
      "        PRON       1.00      1.00      1.00       431\n",
      "       PROPN       1.00      1.00      1.00       708\n",
      "       PUNCT       1.00      1.00      1.00       564\n",
      "       SCONJ       0.98      1.00      0.99        61\n",
      "        VERB       1.00      0.98      0.99       640\n",
      "           X       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           1.00      7611\n",
      "   macro avg       1.00      1.00      1.00      7611\n",
      "weighted avg       1.00      1.00      1.00      7611\n",
      "\n",
      "precision:  0.9968742916302722\n",
      "recall:     0.9968466692944422\n",
      "f1-score:   0.9968472460628419\n",
      "accuracy:   0.9968466692944422\n"
     ]
    }
   ],
   "source": [
    "print(\"MODEL PREDICTION ON TRAINING DATA\".center(50))\n",
    "print(\"-\"*50)\n",
    "\n",
    "y_train_predicted = Model.predict(x_train)\n",
    "\n",
    "print(metrics.flat_classification_report(y_train, y_train_predicted))\n",
    "\n",
    "print('precision: ',  metrics.flat_precision_score(y_train, y_train_predicted, average = 'weighted'))\n",
    "print('recall:    ',  metrics.flat_recall_score(y_train, y_train_predicted, average = 'weighted'))\n",
    "print('f1-score:  ',  metrics.flat_f1_score(y_train, y_train_predicted, average = 'weighted'))\n",
    "print('accuracy:  ',  metrics.flat_accuracy_score(y_train, y_train_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Running the Model on the Testing Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          MODEL PREDICTION ON TEST DATA           \n",
      "--------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ       0.67      0.79      0.73        94\n",
      "         ADP       0.95      0.98      0.96       309\n",
      "         ADV       0.71      0.48      0.57        21\n",
      "         AUX       0.94      0.95      0.95       139\n",
      "       CCONJ       1.00      1.00      1.00        25\n",
      "         DET       0.86      0.89      0.88        36\n",
      "        NOUN       0.77      0.90      0.83       329\n",
      "         NUM       1.00      0.92      0.96        25\n",
      "        PART       1.00      0.97      0.98        33\n",
      "        PRON       0.87      0.85      0.86        65\n",
      "       PROPN       0.65      0.44      0.53       145\n",
      "       PUNCT       1.00      0.84      0.92       135\n",
      "       SCONJ       0.50      0.67      0.57         3\n",
      "        VERB       0.86      0.82      0.84        99\n",
      "\n",
      "    accuracy                           0.85      1458\n",
      "   macro avg       0.84      0.82      0.83      1458\n",
      "weighted avg       0.85      0.85      0.85      1458\n",
      "\n",
      "precision:  0.8513723498048027\n",
      "recall:     0.8511659807956105\n",
      "f1-score:   0.8466764320151978\n",
      "accuracy:   0.8511659807956105\n"
     ]
    }
   ],
   "source": [
    "print(\"MODEL PREDICTION ON TEST DATA\".center(50))\n",
    "print(\"-\"*50)\n",
    "\n",
    "y_test_predicted = Model.predict(x_test)\n",
    "\n",
    "print(metrics.flat_classification_report(y_test, y_test_predicted))\n",
    "\n",
    "print('precision: ',  metrics.flat_precision_score(y_test, y_test_predicted, average = 'weighted'))\n",
    "print('recall:    ',  metrics.flat_recall_score(y_test, y_test_predicted, average = 'weighted'))\n",
    "print('f1-score:  ',  metrics.flat_f1_score(y_test, y_test_predicted, average = 'weighted'))\n",
    "print('accuracy:  ',  metrics.flat_accuracy_score(y_test, y_test_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printTransitions(transitions):\n",
    "    for edge, weight in transitions:\n",
    "        print(\"%-6s =>  %-7s %0.5f\" % (edge[0], edge[1], weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_10_most_common(x_data,y_data,data_set):\n",
    "    Model = CRF(    \n",
    "    algorithm      = 'lbfgs',\n",
    "    c1             = 0.1,\n",
    "    c2             = 0.1,\n",
    "    max_iterations = 300,\n",
    "    all_possible_transitions = True\n",
    "    )\n",
    "    Model.fit(x_data, y_data)\n",
    "    print(\"Top 10 Most Common POS Transition Features:\")\n",
    "    print(\"-\"*21,data_set,\"-\"*21)\n",
    "    printTransitions(Counter(Model.transition_features_).most_common(10))\n",
    "    print(\"\\n\")\n",
    "\n",
    "def print_10_least_common(x_data,y_data,data_set):\n",
    "    Model = CRF( algorithm      = 'lbfgs',\n",
    "    c1             = 0.1,\n",
    "    c2             = 0.1,\n",
    "    max_iterations = 300,\n",
    "    all_possible_transitions = True)\n",
    "    Model.fit(x_data, y_data)\n",
    "    print(\"Top 10 Least Common POS Transition Features:\")\n",
    "    print(\"-\"*21,data_set,\"-\"*21)\n",
    "    printTransitions(Counter(Model.transition_features_).most_common()[-10:])\n",
    "    print(\"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Printing the 10-Most Common and Least-Common Transition Features in TRAINING-SET**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Most Common POS Transition Features:\n",
      "--------------------- Training-set ---------------------\n",
      "ADJ    =>  NOUN    3.99639\n",
      "PROPN  =>  PROPN   3.91982\n",
      "VERB   =>  AUX     3.88266\n",
      "NOUN   =>  VERB    2.71304\n",
      "NOUN   =>  ADP     2.63396\n",
      "DET    =>  NOUN    2.54572\n",
      "NUM    =>  NOUN    2.53846\n",
      "ADJ    =>  VERB    2.33121\n",
      "PROPN  =>  ADP     2.28136\n",
      "NOUN   =>  NOUN    2.17695\n",
      "\n",
      "\n",
      "Top 10 Least Common POS Transition Features:\n",
      "--------------------- Training-set ---------------------\n",
      "COMMA  =>  ADP     -1.34458\n",
      "ADJ    =>  PRON    -1.41543\n",
      "DET    =>  CCONJ   -1.47929\n",
      "ADP    =>  AUX     -1.49491\n",
      "ADP    =>  CCONJ   -1.62925\n",
      "ADP    =>  COMMA   -1.68510\n",
      "ADJ    =>  ADP     -1.80175\n",
      "AUX    =>  ADP     -1.80568\n",
      "CCONJ  =>  AUX     -1.92248\n",
      "DET    =>  ADP     -2.49674\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_10_most_common(x_train,y_train,\"Training-set\")\n",
    "print_10_least_common(x_train,y_train,\"Training-set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Printing the 10-Most Common and Least-Common Transition Features in TEST-SET**\n",
    "\n",
    "**OPTIONAL!!!!!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Most Common POS Transition Features:\n",
      "--------------------- Test-set ---------------------\n",
      "VERB   =>  AUX     3.04655\n",
      "PROPN  =>  PROPN   2.89451\n",
      "ADJ    =>  NOUN    2.81582\n",
      "NOUN   =>  ADP     2.17165\n",
      "PROPN  =>  ADP     2.12235\n",
      "DET    =>  NOUN    1.94831\n",
      "NOUN   =>  VERB    1.91568\n",
      "AUX    =>  AUX     1.83766\n",
      "NUM    =>  NOUN    1.72544\n",
      "ADJ    =>  VERB    1.66722\n",
      "\n",
      "\n",
      "Top 10 Least Common POS Transition Features:\n",
      "--------------------- Test-set ---------------------\n",
      "PROPN  =>  ADJ     -0.93976\n",
      "AUX    =>  ADP     -1.01738\n",
      "PUNCT  =>  PUNCT   -1.01969\n",
      "VERB   =>  PROPN   -1.04201\n",
      "PROPN  =>  AUX     -1.06561\n",
      "ADP    =>  CCONJ   -1.07404\n",
      "DET    =>  PROPN   -1.14494\n",
      "ADJ    =>  ADP     -1.23945\n",
      "AUX    =>  VERB    -1.24320\n",
      "ADP    =>  PUNCT   -1.55589\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_10_most_common(x_test,y_test, \"Test-set\")\n",
    "print_10_least_common(x_test,y_test,\"Test-set\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
